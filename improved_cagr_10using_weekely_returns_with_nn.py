# -*- coding: utf-8 -*-
"""Improved_CAGR_10using_weekely_returns_with_nn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/130lokreMcC1FyNow56VlVT-TKDV5FEbv
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import cvxpy as cp
import matplotlib.pyplot as plt
import seaborn as sns

# ‚úÖ Selected important features
selected_features = [
    'totalEsg', 'highestControversy', 'beta', 'priceToBook',
    'priceToSalesTrailing12Months', 'trailingPE', 'profitMargins',
    '52WeekChange', 'revenueQuarterlyGrowth', 'averageVolume'
]

# Load ESG, financial, and stock price datasets
esg_data = pd.read_csv("esg_scores_2021.csv")
financial_data = pd.read_csv("filtered_security_data.csv")
price_data = pd.read_csv("snp500_stocks_closing_price_daily_data.csv")

# Clean NaN columns
esg_data.dropna(axis=1, how='all', inplace=True)
financial_data.dropna(axis=1, how='all', inplace=True)
price_data.dropna(axis=1, how='all', inplace=True)

# Merge ESG & Financial Data
data = esg_data.merge(financial_data, on="symbol", how="inner")
print("‚úÖ Data Loaded & Merged:", data.shape)

# Filter by ESG score and controversy
esg_threshold = data['totalEsg'].median()
selected_stocks = data[(data['totalEsg'] >= esg_threshold) & (data['highestControversy'] <= 2)]

# Initial Portfolio
initial_portfolio = selected_stocks[['symbol', 'totalEsg', 'sector']]
initial_weights = np.full(len(initial_portfolio), 1 / len(initial_portfolio))
portfolio = pd.DataFrame({'symbol': initial_portfolio['symbol'], 'weight': initial_weights})
print("‚úÖ Initial Portfolio Created:", portfolio.shape)

# Reshape price data
price_data_melted = price_data.melt(id_vars=["symbol"], var_name="date", value_name="closing_price")
price_data_melted["date"] = pd.to_datetime(price_data_melted["date"], errors='coerce')
price_data_melted = price_data_melted.sort_values(["symbol", "date"])

# Compute daily returns
# In price_data_melted preprocessing section
price_data_melted["weekly_return"] = price_data_melted.groupby("symbol")["closing_price"].pct_change(periods=5)
price_data_melted.dropna(inplace=True)


def train_neural_network_for_returns(data, price_data_melted, selected_features):
    df_merged = price_data_melted.merge(data, on="symbol", how="inner")

    features_available = [f for f in selected_features if f in df_merged.columns]
    columns_to_keep = ["symbol", "date", "closing_price", "weekly_return"] + features_available
    df_merged = df_merged[columns_to_keep]

    df_merged[features_available] = df_merged[features_available].fillna(df_merged[features_available].median())

    X = df_merged[features_available]
    y = df_merged["weekly_return"]

    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)

    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

    model = tf.keras.Sequential([
        layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),
        layers.Dense(32, activation='relu'),
        layers.Dense(1, activation='linear')
    ])
    model.compile(optimizer='adam', loss='mse', metrics=['mae'])

    history = model.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_test, y_test))
    return model, scaler, X_scaled, history, df_merged


def optimize_portfolio(nn_model, df_merged, scaler, selected_features):
    print("\nüöÄ Optimizing Portfolio Allocation...")

    features_available = [f for f in selected_features if f in df_merged.columns]
    X_new = df_merged[features_available]
    X_new_scaled = scaler.transform(X_new)

    predicted_returns = nn_model.predict(X_new_scaled).flatten()
    df_merged['predicted_return'] = predicted_returns

    stock_return = df_merged.groupby("symbol")["predicted_return"].mean()

    return_pivot = df_merged.pivot(index="date", columns="symbol", values="weekly_return")
    return_pivot = return_pivot.dropna(axis=1, how='any')
    cov_matrix = return_pivot.cov()

    common_symbols = list(set(stock_return.index).intersection(set(cov_matrix.columns)))
    stock_return = stock_return[common_symbols]
    cov_matrix = cov_matrix.loc[common_symbols, common_symbols]

    n = len(stock_return)
    w = cp.Variable(n)
    ret = stock_return.values
    risk = cp.quad_form(w, cov_matrix.values)

    objective = cp.Maximize(ret @ w - 0.5 * risk)
    constraints = [cp.sum(w) == 1, w >= 0]

    problem = cp.Problem(objective, constraints)
    problem.solve()

    optimal_weights = w.value
    optimal_portfolio = pd.DataFrame({
        "symbol": stock_return.index,
        "weight": optimal_weights
    }).sort_values(by="weight", ascending=False)

    print("‚úÖ Portfolio Optimization Complete. Top Allocations:")
    print(optimal_portfolio.head(10))

    return optimal_portfolio

# üß† Train Neural Network
nn_model, scaler, X_scaled, history, df_merged = train_neural_network_for_returns(data, price_data_melted, selected_features)
print("‚úÖ Neural Network Trained")

# üìà Optimize Portfolio Allocation
optimized_portfolio = optimize_portfolio(nn_model, df_merged, scaler, selected_features)

# # üîÅ STEP 4: Backtest Optimized Portfolio vs S&P 500
# import matplotlib.pyplot as plt

# # Load S&P 500 Index data
# sp500_index_data = pd.read_csv("snp500_INDEX_daily_closing_prices.csv")
# sp500_index_data["date"] = pd.to_datetime(sp500_index_data["Date"])
# sp500_index_data = sp500_index_data.sort_values("date")
# sp500_index_data["daily_return"] = sp500_index_data["Close Price"].pct_change()
# sp500_index_data = sp500_index_data.dropna(subset=["daily_return"])

# # Prepare Portfolio Daily Returns
# selected_symbols = optimized_portfolio["symbol"].tolist()
# weights_dict = optimized_portfolio.set_index("symbol")["weight"].to_dict()

# # Filter melted stock prices
# filtered_price_data = price_data_melted[price_data_melted["symbol"].isin(selected_symbols)]

# # Pivot to wide format: date x symbol
# pivot_prices = filtered_price_data.pivot(index="date", columns="symbol", values="closing_price")
# pivot_prices = pivot_prices.dropna()

# # Calculate daily returns
# daily_returns = pivot_prices.pct_change().dropna()

# # Align weights with columns
# aligned_weights = np.array([weights_dict[symbol] for symbol in daily_returns.columns])

# # Calculate portfolio daily returns
# portfolio_daily_returns = daily_returns.dot(aligned_weights)

# # Cumulative Returns
# portfolio_cumulative_returns = (1 + portfolio_daily_returns).cumprod()
# sp500_cumulative_returns = (1 + sp500_index_data.set_index("date")["daily_return"]).cumprod()

# # Align dates
# common_dates = portfolio_cumulative_returns.index.intersection(sp500_cumulative_returns.index)
# portfolio_cumulative_returns = portfolio_cumulative_returns.loc[common_dates]
# sp500_cumulative_returns = sp500_cumulative_returns.loc[common_dates]

# # CAGR Calculation
# def calculate_cagr(cumulative_returns):
#     total_days = (cumulative_returns.index[-1] - cumulative_returns.index[0]).days
#     num_years = total_days / 365.25
#     final_return = cumulative_returns.iloc[-1]
#     return (final_return ** (1 / num_years) - 1) * 100

# portfolio_cagr = calculate_cagr(portfolio_cumulative_returns)
# sp500_cagr = calculate_cagr(sp500_cumulative_returns)

# # Plotting
# plt.figure(figsize=(12, 6))
# plt.plot(portfolio_cumulative_returns, label=f"üìà Optimized Portfolio (CAGR: {portfolio_cagr:.2f}%)", linewidth=2)
# plt.plot(sp500_cumulative_returns, label=f"üèõÔ∏è S&P 500 Index (CAGR: {sp500_cagr:.2f}%)", linestyle='--', linewidth=2)
# plt.title("üìä Backtest: Optimized Portfolio vs. S&P 500 Index")
# plt.xlabel("Date")
# plt.ylabel("Cumulative Return")
# plt.legend()
# plt.grid(True)
# plt.tight_layout()
# plt.show()

###Backtest using Weekely Returns
# üîÅ STEP 4: Backtest Optimized Portfolio vs S&P 500 (Weekly)
import matplotlib.pyplot as plt

# Load S&P 500 Index data
sp500_index_data = pd.read_csv("snp500_INDEX_daily_closing_prices.csv")
sp500_index_data["date"] = pd.to_datetime(sp500_index_data["Date"])
sp500_index_data = sp500_index_data.sort_values("date")
sp500_index_data.set_index("date", inplace=True)

# Convert to weekly prices and calculate weekly returns
sp500_weekly_prices = sp500_index_data["Close Price"].resample("W").last()
sp500_weekly_returns = sp500_weekly_prices.pct_change().dropna()
sp500_cumulative_returns = (1 + sp500_weekly_returns).cumprod()

# Prepare Portfolio Weekly Returns
selected_symbols = optimized_portfolio["symbol"].tolist()
weights_dict = optimized_portfolio.set_index("symbol")["weight"].to_dict()

# Filter melted stock prices
filtered_price_data = price_data_melted[price_data_melted["symbol"].isin(selected_symbols)]

# Pivot to wide format: date x symbol
pivot_prices = filtered_price_data.pivot(index="date", columns="symbol", values="closing_price")
pivot_prices = pivot_prices.dropna()
pivot_prices.index = pd.to_datetime(pivot_prices.index)

# Convert to weekly prices and calculate weekly returns
weekly_prices = pivot_prices.resample("W").last()
weekly_returns = weekly_prices.pct_change().dropna()

# Align weights with columns
aligned_weights = np.array([weights_dict[symbol] for symbol in weekly_returns.columns])

# Calculate portfolio weekly returns
portfolio_weekly_returns = weekly_returns.dot(aligned_weights)
portfolio_cumulative_returns = (1 + portfolio_weekly_returns).cumprod()

# Align dates
common_dates = portfolio_cumulative_returns.index.intersection(sp500_cumulative_returns.index)
portfolio_cumulative_returns = portfolio_cumulative_returns.loc[common_dates]
sp500_cumulative_returns = sp500_cumulative_returns.loc[common_dates]

# CAGR Calculation
def calculate_cagr(cumulative_returns):
    total_days = (cumulative_returns.index[-1] - cumulative_returns.index[0]).days
    num_years = total_days / 365.25
    final_return = cumulative_returns.iloc[-1]
    return (final_return ** (1 / num_years) - 1) * 100

portfolio_cagr = calculate_cagr(portfolio_cumulative_returns)
sp500_cagr = calculate_cagr(sp500_cumulative_returns)

# Plotting
plt.figure(figsize=(12, 6))
plt.plot(portfolio_cumulative_returns, label=f"üìà Optimized Portfolio (CAGR: {portfolio_cagr:.2f}%)", linewidth=2)
plt.plot(sp500_cumulative_returns, label=f"üèõÔ∏è S&P 500 Index (CAGR: {sp500_cagr:.2f}%)", linestyle='--', linewidth=2)
plt.title("üìä Backtest (Weekly): Optimized Portfolio vs. S&P 500 Index")
plt.xlabel("Date")
plt.ylabel("Cumulative Return")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()